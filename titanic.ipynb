{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TITANIC** **SURVIVAL** **PREDICTION**"
      ],
      "metadata": {
        "id": "oVOslHR98tl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction:\n",
        "\n",
        "In this beginner-friendly project, I will delve into the Titanic dataset to build a predictive model that can determine whether a passenger survived the disaster or not. By exploring various attributes such as passenger class, age, gender, and embarkation point, I aim to uncover patterns and insights that might shed light on the factors that influenced survival rates.\n",
        "\n",
        "I will follow a structured approach, starting with data loading and exploration, followed by preprocessing to handle missing values and convert categorical variables into numeric form. Then, I'll split the dataset into training and testing sets, build a logistic regression model, and evaluate its performance using accuracy metrics, confusion matrix, and classification report.\n",
        "\n",
        "Through this project, I have not only gain hands-on experience in data preprocessing and predictive modeling but also pay homage to the individuals who were affected by this tragic event. Let's embark on this journey to uncover insights from the Titanic dataset and build a model that can predict survival outcomes with reasonable accuracy."
      ],
      "metadata": {
        "id": "Y7L_TjbX9aTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "IimihrMe85mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "titanic_data = pd.read_csv(\"/content/Titanic-Dataset.csv\")"
      ],
      "metadata": {
        "id": "bk7rLNhw-tzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the data\n",
        "print(titanic_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU65x_fH-txn",
        "outputId": "b08d25e4-fbe2-46af-e777-86a9a1d2239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "titanic_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True) # Drop unnecessary columns\n",
        "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1}) # Convert 'Sex' to numeric\n",
        "titanic_data['Embarked'] = titanic_data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}) # Convert 'Embarked' to numeric\n",
        "titanic_data.fillna(titanic_data.mean(), inplace=True) # Fill missing values with mean"
      ],
      "metadata": {
        "id": "EaSgrIls85n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target variable\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']"
      ],
      "metadata": {
        "id": "NKm0BLp5_Zhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uFNnhikY_h2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "oZ-4MPB5AjXb",
        "outputId": "98563524-8748-4411-8e78-fa74d7339ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "rHRZ4Yv3AjWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "1SrBc5jZAzk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3IZiqqMA7m5",
        "outputId": "99ea01e0-7891-4a75-8da4-8b263a0eff8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7988826815642458\n",
            "Confusion Matrix:\n",
            " [[89 16]\n",
            " [20 54]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83       105\n",
            "           1       0.77      0.73      0.75        74\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.79      0.79      0.79       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shows the evaluation metrics of the logistic regression model applied to the Titanic dataset:\n",
        "\n",
        "Accuracy: 0.7988826815642458 (approximately 79.89%)\n",
        "  This metric represents the proportion of correct predictions out of all predictions made. In this case, the model achieved an accuracy of approximately 79.89%, indicating that it correctly predicted the survival outcome for about 79.89% of the passengers in the test dataset.\n",
        "\n",
        "Confusion Matrix:\n",
        "[[89 16]\n",
        "[20 54]]\n",
        "  The confusion matrix provides a breakdown of correct and incorrect predictions made by the model. It consists of four terms:\n",
        "    - True Positive (TP): 89 (Predicted as survived and actually survived)\n",
        "    - False Positive (FP): 16 (Predicted as survived but actually did not survive)\n",
        "    - False Negative (FN): 20 (Predicted as not survived but actually survived)\n",
        "    - True Negative (TN): 54 (Predicted as not survived and actually did not survive)\n",
        "\n",
        "- Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "           0       0.82      0.85      0.83       105\n",
        "           1       0.77      0.73      0.75        74\n",
        "\n",
        "    accuracy                           0.80       179\n",
        "   macro avg       0.79      0.79      0.79       179\n",
        "weighted avg       0.80      0.80      0.80       179\n",
        "\n",
        "  The classification report provides precision, recall, and F1-score for each class (0 - not survived, 1 - survived), as well as their averages. Precision measures the proportion of true positive predictions out of all positive predictions made, recall measures the proportion of true positive predictions out of all actual positive instances, and F1-score is the harmonic mean of precision and recall. The report also includes support, which represents the number of instances of each class in the test set.\n",
        "\n",
        "Overall, the logistic regression model achieved a relatively good performance in predicting survival outcomes, with an accuracy of approximately 79.89%. However, further analysis and possibly model improvement could be explored to enhance its performance."
      ],
      "metadata": {
        "id": "-ZNdGPLkDAJl"
      }
    }
  ]
}